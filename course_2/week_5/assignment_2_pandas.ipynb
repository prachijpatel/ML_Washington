{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, 'sqft_living15':float, 'grade':int, 'yr_renovated':int, 'price':float, 'bedrooms':float, 'zipcode':str, 'long':float, 'sqft_lot15':float, 'sqft_living':float, 'floors':str, 'condition':int, 'lat':float, 'date':str, 'sqft_basement':int, 'yr_built':int, 'id':str, 'sqft_lot':int, 'view':int}\n",
    "\n",
    "sales = pd.read_csv('../data/kc_house_data.csv', dtype=dtype_dict)\n",
    "train=pd.read_csv('../data/kc_house_train_data.csv',dtype=dtype_dict)\n",
    "test=pd.read_csv('../data/kc_house_test_data.csv',dtype=dtype_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_data(data_sframe, features, output):\n",
    "    data_sframe['constant'] = 1 # this is how you add a constant column to an SFrame\n",
    "    # add the column 'constant' to the front of the features list so that we can extract it along with the others:\n",
    "    features = ['constant'] + features # this is how you combine two lists\n",
    "    # select the columns of data_SFrame given by the features list into the SFrame features_sframe (now including constant):\n",
    "    features_sframe=data_sframe[features]\n",
    "    # the following line will convert the features_SFrame into a numpy matrix:\n",
    "    feature_matrix = features_sframe.to_numpy()\n",
    "    # assign the column of data_sframe associated with the output to the SArray output_sarray\n",
    "    output_array=data_sframe[output].to_numpy()\n",
    "    # the following will convert the SArray into a numpy array by first converting it to a list\n",
    "#     output_array = output_sarray.to_numpy()\n",
    "    return(feature_matrix, output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_output(feature_matrix, weights):\n",
    "    # assume feature_matrix is a numpy matrix containing the features as columns and weights is a corresponding numpy array\n",
    "    # create the predictions vector by using np.dot()\n",
    "    predictions = np.dot(feature_matrix, weights)\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(features):\n",
    "    norms = np.linalg.norm(X, axis=0)\n",
    "    X_normalized = X / norms\n",
    "    return (normalized_features, norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cost(predictions,output,weights,lam):\n",
    "#     c=[(prediction - output)^2].sum() + lam*(abs(weights).sum())\n",
    "#     return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(feature_matrix):\n",
    "    norms = np.linalg.norm(feature_matrix, axis=0)\n",
    "    normalized_features = feature_matrix/ norms\n",
    "    return (normalized_features, norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_coordinate_descent_step(i, feature_matrix, output, weights, l1_penalty):\n",
    "    # compute prediction\n",
    "    prediction = predict_output(feature_matrix,weights)\n",
    "#     prediction = \n",
    "    # compute ro[i] = SUM[ [feature_i]*(output - prediction + weight[i]*[feature_i]) ]\n",
    "    ro_i=np.sum([[feature_matrix[:,i]]*(output - prediction + np.dot(weights[i],[feature_matrix[:,i]])) ])\n",
    "\n",
    "    if i == 0: # intercept -- do not regularize\n",
    "        new_weight_i = ro_i \n",
    "    elif ro_i < -l1_penalty/2.:\n",
    "        new_weight_i = ro_i+l1_penalty/2\n",
    "    elif ro_i > l1_penalty/2.:\n",
    "        new_weight_i = ro_i-l1_penalty/2\n",
    "    else:\n",
    "        new_weight_i = 0.\n",
    "    \n",
    "    return new_weight_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_cyclical_coordinate_descent(feature_matrix, output, initial_weights, l1_penalty, tolerance):\n",
    "    converged = False\n",
    "    weights =np.array(initial_weights) # make sure it's a numpy array\n",
    "#     print(initial_weights)\n",
    "    while not converged:\n",
    "        w_diff=[]\n",
    "        for i in range(len(weights)):\n",
    "            old_weights_i = weights[i]\n",
    "            weights[i] = lasso_coordinate_descent_step(i, feature_matrix, output, weights, l1_penalty)\n",
    "            w_diff.append(old_weights_i-weights[i])\n",
    "        if max(w_diff)<tolerance:\n",
    "            converged=True\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_features = ['sqft_living', 'bedrooms']\n",
    "my_output = 'price'\n",
    "(simple_feature_matrix, output) = get_numpy_data(sales, simple_features, my_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_feature_matrix, norms = normalize_features(simple_feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array([1., 4., 1.])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[221900. 538000. 180000. ... 402101. 400000. 325000.]\n"
     ]
    }
   ],
   "source": [
    "prediction = predict_output(simple_feature_matrix,weights)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv(\"../data/kc_house_train_data.csv\",dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features = ['bedrooms',\n",
    "                'bathrooms',\n",
    "                'sqft_living',\n",
    "                'sqft_lot',\n",
    "                'floors',\n",
    "                'waterfront', \n",
    "                'view', \n",
    "                'condition', \n",
    "                'grade',\n",
    "                'sqft_above',\n",
    "                'sqft_basement',\n",
    "                'yr_built', \n",
    "                'yr_renovated']\n",
    "len(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "(feature_matrix, output) = get_numpy_data(train_data, all_features, my_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix=feature_matrix.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_features,simple_norms=normalize_features(feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.31848398e+02, 4.60040216e+02, 2.96850552e+02, 2.99962419e+05,\n",
       "       5.81709718e+06, 2.09458827e+02, 1.15325626e+01, 1.05933942e+02,\n",
       "       4.57793622e+02, 1.02101959e+03, 2.59726472e+05, 7.01224951e+04,\n",
       "       2.59922094e+05, 5.36953839e+04])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00758447, 0.00652117, 0.0033687 , ..., 0.        , 0.00752148,\n",
       "        0.        ],\n",
       "       [0.00758447, 0.00652117, 0.00757957, ..., 0.0057043 , 0.0075061 ,\n",
       "        0.03707954],\n",
       "       [0.00758447, 0.00434745, 0.0033687 , ..., 0.        , 0.00743684,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.00758447, 0.00652117, 0.00842175, ..., 0.        , 0.00772924,\n",
       "        0.        ],\n",
       "       [0.00758447, 0.00652117, 0.00842175, ..., 0.        , 0.00771   ,\n",
       "        0.        ],\n",
       "       [0.00758447, 0.00434745, 0.00252652, ..., 0.        , 0.00772539,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "l1_penalty = 1e7\n",
    "tolerance = 1.0\n",
    "initial_weights=np.zeros(len(all_features)+1)\n",
    "print(initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights1e7 = lasso_cyclical_coordinate_descent(normalize_features, output,\n",
    "                                            initial_weights, l1_penalty, tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24429600.23440312,        0.        ,        0.        ,\n",
       "       48389174.77154896,        0.        ,        0.        ,\n",
       "        3317511.21492165,  7329961.81171425,        0.        ,\n",
       "              0.        ,        0.        ,        0.        ,\n",
       "              0.        ,        0.        ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights1e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept        2.442960e+07\n",
       "bedrooms         0.000000e+00\n",
       "bathrooms        0.000000e+00\n",
       "sqft_living      4.838917e+07\n",
       "sqft_lot         0.000000e+00\n",
       "floors           0.000000e+00\n",
       "waterfront       3.317511e+06\n",
       "view             7.329962e+06\n",
       "condition        0.000000e+00\n",
       "grade            0.000000e+00\n",
       "sqft_above       0.000000e+00\n",
       "sqft_basement    0.000000e+00\n",
       "yr_built         0.000000e+00\n",
       "yr_renovated     0.000000e+00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(weights1e7,index=['intercept']+all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([71114625.71488702,        0.        ,        0.        ,\n",
       "              0.        ,        0.        ,        0.        ,\n",
       "              0.        ,        0.        ,        0.        ,\n",
       "              0.        ,        0.        ,        0.        ,\n",
       "              0.        ,        0.        ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_penalty = 1e8\n",
    "tolerance = 1.0\n",
    "initial_weights=np.zeros(len(all_features)+1)\n",
    "weights1e8 = lasso_cyclical_coordinate_descent(normalize_features, output,\n",
    "                                            initial_weights, l1_penalty, tolerance)\n",
    "weights1e8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept        7.111463e+07\n",
       "bedrooms         0.000000e+00\n",
       "bathrooms        0.000000e+00\n",
       "sqft_living      0.000000e+00\n",
       "sqft_lot         0.000000e+00\n",
       "floors           0.000000e+00\n",
       "waterfront       0.000000e+00\n",
       "view             0.000000e+00\n",
       "condition        0.000000e+00\n",
       "grade            0.000000e+00\n",
       "sqft_above       0.000000e+00\n",
       "sqft_basement    0.000000e+00\n",
       "yr_built         0.000000e+00\n",
       "yr_renovated     0.000000e+00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(weights1e8,index=['intercept']+all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 76952003.53436852, -21577770.46155855,  15724329.40694158,\n",
       "        83382212.59479392,  -2016684.51627024,  -5518113.00193007,\n",
       "         6482223.88448927,   7253631.09099746,   2046534.02912275,\n",
       "         8241759.62585616,  -6736050.93130816,  -2956206.20723013,\n",
       "       -75906661.13572001,   2777206.4031928 ])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_penalty = 1e4\n",
    "tolerance = 5e5\n",
    "initial_weights=np.zeros(len(all_features)+1)\n",
    "weights1e4 = lasso_cyclical_coordinate_descent(normalize_features, output,\n",
    "                                            initial_weights, l1_penalty, tolerance)\n",
    "weights1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept        7.695200e+07\n",
       "bedrooms        -2.157777e+07\n",
       "bathrooms        1.572433e+07\n",
       "sqft_living      8.338221e+07\n",
       "sqft_lot        -2.016685e+06\n",
       "floors          -5.518113e+06\n",
       "waterfront       6.482224e+06\n",
       "view             7.253631e+06\n",
       "condition        2.046534e+06\n",
       "grade            8.241760e+06\n",
       "sqft_above      -6.736051e+06\n",
       "sqft_basement   -2.956206e+06\n",
       "yr_built        -7.590666e+07\n",
       "yr_renovated     2.777206e+06\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(weights1e4,index=['intercept']+all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([539366.62793373,      0.        ,      0.        ,      0.        ,\n",
       "            0.        ,      0.        ,      0.        ,      0.        ,\n",
       "            0.        ,      0.        ,      0.        ,      0.        ,\n",
       "            0.        ,      0.        ])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_normalized = weights / norms\n",
    "weights1e4_normalized=weights1e4/simple_norms\n",
    "weights1e7_normalized=weights1e7/simple_norms\n",
    "weights1e8_normalized=weights1e8/simple_norms\n",
    "weights1e8_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rss(predictions,output):\n",
    "    RSS=predictions-output\n",
    "    RSS=RSS*RSS\n",
    "    RSS=RSS.sum()\n",
    "    return RSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=pd.read_csv(\"../data/kc_house_test_data.csv\",dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_feature_matrix, test_output) = get_numpy_data(test_data, all_features, 'price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232202384262612.44\n"
     ]
    }
   ],
   "source": [
    "predictions=predict_output(test_feature_matrix.astype(float),weights1e4_normalized)\n",
    "print(get_rss(predictions,test_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275962075920366.78\n"
     ]
    }
   ],
   "source": [
    "predictions=predict_output(test_feature_matrix.astype(float),weights1e7_normalized)\n",
    "print(get_rss(predictions,test_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537166151497322.75\n"
     ]
    }
   ],
   "source": [
    "predictions=predict_output(test_feature_matrix.astype(float),weights1e8_normalized)\n",
    "print(get_rss(predictions,test_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
